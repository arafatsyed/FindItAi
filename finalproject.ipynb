{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finalproject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+9yuqMhYjcPW+ZFzgg8OT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arafatsyed/FindItAi/blob/main/finalproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do0W9Pmciu91"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from  torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EJh8RLMiyir",
        "outputId": "47988595-2888-41b9-ac77-1c49e6ea16bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "training_dataset = ImageFolder('/content/drive/MyDrive/APS360/new_training',transform=transform)\n",
        "validation_dataset = ImageFolder('/content/drive/MyDrive/APS360/new_validation',transform=transform)\n",
        "testing_dataset = ImageFolder('/content/drive/MyDrive/APS360/new_testing',transform=transform);\n"
      ],
      "metadata": {
        "id": "_3Gm_9W3i4Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_dataset.class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnJESy-FjNjS",
        "outputId": "134ec6f9-746d-4b40-97f7-0b734ae1ac85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dhaka': 0, 'johannesburg': 1, 'manhattan': 2, 'paris': 3, 'sao_paulo': 4, 'seoul': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models\n",
        "alexnet = torchvision.models.alexnet(pretrained=True)\n"
      ],
      "metadata": {
        "id": "1EUuEuVijYJn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52,
          "referenced_widgets": [
            "23a7bd2a308c40b183f5b948477dca8d"
          ]
        },
        "outputId": "2a2ab5fa-0b9f-4e16-e12f-69130fe5d919"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23a7bd2a308c40b183f5b948477dca8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_net = torchvision.models.resnet50(pretrained=True)\n",
        "res_net_conv = nn.Sequential(*list(res_net.children())[:-2])\n",
        "res_net_conv.training = False"
      ],
      "metadata": {
        "id": "Ij7CmZKwt5xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(res_net_conv,input_size=(3,224,224))"
      ],
      "metadata": {
        "id": "VGxcPGXA0NF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "#Get data in batch size of 1 (out put 1x3x244x244)\n",
        "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size,num_workers=1)\n",
        "val_loader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size,num_workers=1)\n",
        "test_loader = torch.utils.data.DataLoader(testing_dataset,batch_size=batch_size,num_workers=1)\n",
        "\n",
        "for img,label in train_loader:\n",
        "  print(img.shape)\n",
        "  features = res_net_conv(img)\n",
        "  print(features.shape)\n",
        "  \n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJt8O-zjuAaG",
        "outputId": "6efc684e-bc3b-4b3d-b5b0-cb3d726e0b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 224, 224])\n",
            "torch.Size([1, 2048, 7, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "batch_size = 1\n",
        "#Get data in batch size of 1 (out put 1x3x244x244)\n",
        "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size,num_workers=1)\n",
        "val_loader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size,num_workers=1)\n",
        "test_loader = torch.utils.data.DataLoader(testing_dataset,batch_size=batch_size,num_workers=1)\n",
        "\n",
        "labels = ['dhaka','johannesburg','manhattan','paris','sao_paulo','seoul']\n",
        "\n",
        "#location on my local drive\n",
        "folderpath = \"/content/drive/MyDrive/APS360/resnet_features\"\n",
        "train_dir = os.path.join(folderpath,'train/')\n",
        "val_dir = os.path.join(folderpath,'val/')\n",
        "test_dir = os.path.join(folderpath,'test/')\n",
        "\n",
        "#function saves data as folders labeled A, B, C etc\n",
        "#to use datasetFolder to easily get these tensors\n",
        "def save_alexnet_featues(dataset,path):\n",
        "  pic_id = 0\n",
        "  for image,label in dataset:\n",
        "    #features = alexnet.features(image)\n",
        "    features = res_net_conv(image)\n",
        "    #remove gradient\n",
        "    features = torch.from_numpy(features.detach().numpy()).squeeze(0)\n",
        "    torch.save(features, path + str(labels[label]) + '/' + str(pic_id) +'_'+str(labels[label]) + '.tensor')\n",
        "    pic_id+=1\n"
      ],
      "metadata": {
        "id": "_FgbdNp5jccE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save_alexnet_featues(train_loader,train_dir)\n",
        "#save_alexnet_featues(val_loader,val_dir)\n",
        "#save_alexnet_featues(test_loader,test_dir)"
      ],
      "metadata": {
        "id": "Esm7GGQokFGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load in tensors from alex net\n",
        "training_dataset = torchvision.datasets.DatasetFolder('/content/drive/MyDrive/APS360/new_features/train',loader = torch.load, extensions=('.tensor'))\n",
        "validation_dataset =  torchvision.datasets.DatasetFolder('/content/drive/MyDrive/APS360/new_features/val',loader = torch.load, extensions=('.tensor'))\n",
        "testing_dataset =  torchvision.datasets.DatasetFolder('/content/drive/MyDrive/APS360/new_features/test',loader = torch.load, extensions=('.tensor'))\n",
        "\n",
        "#load tensors from res_net\n",
        "# training_dataset = torchvision.datasets.DatasetFolder('/content/drive/MyDrive/APS360/resnet_features/train',loader = torch.load, extensions=('.tensor'))\n",
        "# validation_dataset =  torchvision.datasets.DatasetFolder('/content/drive/MyDrive/APS360/resnet_features/val',loader = torch.load, extensions=('.tensor'))\n",
        "# testing_dataset =  torchvision.datasets.DatasetFolder('/content/drive/MyDrive/APS360/resnet_features/test',loader = torch.load, extensions=('.tensor'))\n",
        "\n",
        "print(testing_dataset[0][1])\n",
        "print(testing_dataset.class_to_idx)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldwYwKkZlLiE",
        "outputId": "1685eebf-d5d2-4ac6-c030-d786f4cceec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "{'dhaka': 0, 'johannesburg': 1, 'manhattan': 2, 'paris': 3, 'sao_paulo': 4, 'seoul': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetANNClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ResNetANNClassifier,self).__init__()\n",
        "    self.name = \"ResNetANN\"\n",
        "    self.fc1 = nn.Linear(2048*7*7,5000)\n",
        "    self.fc2 = nn.Linear(5000,32)\n",
        "    self.fc3 = nn.Linear(32,6)\n",
        "  \n",
        "    self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.view(-1,2048*7*7)\n",
        "    #x = self.dropout(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "   # x = self.dropout(x)\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc3(x)\n",
        "    return x;\n",
        "\n"
      ],
      "metadata": {
        "id": "W12yzj0dlZNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ANNClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ANNClassifier,self).__init__()\n",
        "    self.name = \"ANN\"\n",
        "    self.fc1 = nn.Linear(256*6*6,500)\n",
        "    #self.fc2 = nn.Linear(500,32)\n",
        "    self.fc3 = nn.Linear(500,6)\n",
        "\n",
        "    self.dropout = nn.Dropout(0.15)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.view(-1,256*6*6)\n",
        "    #x = self.dropout(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "   # x = self.dropout(x)\n",
        "    #x = F.relu(self.fc2(x))\n",
        "    #x = self.dropout(x)\n",
        "    x = self.fc3(x)\n",
        "    return x;\n",
        "\n"
      ],
      "metadata": {
        "id": "qE14N-iEl4GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GestureNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GestureNet, self).__init__()\n",
        "    self.name=\"gesture\"\n",
        "    self.conv1 = nn.Conv2d(3, 10, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(10, 10, 5)\n",
        "    self.fc1 = nn.Linear(10 * 53 * 53, 500)\n",
        "    self.fc2 = nn.Linear(500, 6)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(x.size(0), 10*53*53)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    x = x.squeeze(1) # Flatten to [batch_size]\n",
        "    return x        \n",
        "\n"
      ],
      "metadata": {
        "id": "LVnBtOXnWFvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = True"
      ],
      "metadata": {
        "id": "QuVou0RPmmqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"/content/drive/MyDrive/APS360/models/model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path\n",
        "\n",
        "#takes the model, the dataset to test on, returns the accuracy on that dataset\n",
        "def get_accuracy(net,data,train=False):\n",
        "\n",
        "  labels = ['dhaka','johannesburg','manhattan','paris','sao_paulo','seoul']\n",
        "  cor = 0\n",
        "  total = 0\n",
        "  total_class = np.zeros(6)\n",
        "  total_correct = np.zeros(6)\n",
        "  total_pred = np.zeros(6)\n",
        "  for img,label in iter(data):\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "      img=img.cuda()\n",
        "      label=label.cuda()\n",
        "    output = net(img)\n",
        "    pred=output.max(1,keepdim=True)[1]\n",
        "    \n",
        "    index = 0\n",
        "    for i in pred:\n",
        "      total_pred[i]+=1\n",
        "      \n",
        "      total_class[label[index]]+=1\n",
        "      if(i==label[index]):\n",
        "        total_correct[i]+=1\n",
        "      index+=1\n",
        "    #print(total_class,total_correct,total_pred)\n",
        "    #return 1\n",
        "    cor +=pred.eq(label.view_as(pred)).sum().item()\n",
        "    total +=img.shape[0]\n",
        "    #print(cor)\n",
        "  print(total_class,total_correct,total_pred)\n",
        "  return cor/total\n",
        "\n",
        "def train_net(net, batch_size=64,learning_rate=0.01,num_epochs=30,custom=False):\n",
        "\n",
        "  torch.manual_seed(1000)\n",
        "\n",
        "  #shuffle data\n",
        "  if(not custom):\n",
        "    train_loader = torch.utils.data.DataLoader(training_dataset,batch_size=batch_size,shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size,shuffle=True)\n",
        "  # else:\n",
        "  #   train_loader = torch.utils.data.DataLoader(custom_img,batch_size=batch_size,shuffle=True)\n",
        "  #   val_loader = torch.utils.data.DataLoader(validation_dataset,batch_size=512,shuffle=True)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(net.parameters(),lr=learning_rate,momentum=0.9)\n",
        "\n",
        "  train_err = np.zeros(num_epochs)\n",
        "  train_loss = np.zeros(num_epochs)\n",
        "\n",
        "  train_acc = np.zeros(num_epochs)\n",
        "  train_loss = np.zeros(num_epochs)\n",
        "  val_acc = np.zeros(num_epochs)\n",
        "  val_loss = np.zeros(num_epochs)  \n",
        "\n",
        "\n",
        "  #iters,losses,train_acc,val_acc = [],[],[],[]\n",
        "  epochs=[]\n",
        "  n=0\n",
        "  cor=0\n",
        "  total=0\n",
        "  print(\"starting training\")\n",
        "  for epoch in range(num_epochs):\n",
        "    cor=0\n",
        "    total=0\n",
        "    total_train_loss = 0.0\n",
        "    total_val_loss = 0.0\n",
        "    i=0\n",
        "    for inputs,labels in iter(train_loader):\n",
        "     \n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()     \n",
        "\n",
        "      output = net(inputs)\n",
        "      loss=criterion(output,labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      #loss\n",
        "      total_train_loss += loss.item()\n",
        "      i+=1\n",
        "\n",
        "      #mini batch accuracy\n",
        "      pred = output.max(1,keepdim=True)[1]\n",
        "      cor +=pred.eq(labels.view_as(pred)).sum().item()\n",
        "      total+=labels.shape[0]\n",
        "\n",
        "    train_acc[epoch]=(cor/total) \n",
        "    train_loss[epoch]=(float(total_train_loss)/(i+1))\n",
        "\n",
        "    i=0\n",
        "    cor=0\n",
        "    total=0\n",
        "    for inputs,labels in iter(val_loader):\n",
        "      \n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()     \n",
        "      #get output and calculate loss\n",
        "      output = net(inputs)\n",
        "      loss = criterion(output,labels)\n",
        "      total_val_loss += loss.item()\n",
        "      i+=1\n",
        "\n",
        "      #calculate accuracy\n",
        "      pred = output.max(1,keepdim=True)[1]\n",
        "      cor +=pred.eq(labels.view_as(pred)).sum().item()\n",
        "      total+=labels.shape[0]\n",
        "    \n",
        "    val_acc[epoch]=(cor/total)\n",
        "    val_loss[epoch]=(float(total_val_loss)/(i+1))\n",
        "\n",
        "    epochs.append(epoch)\n",
        "    print(\"Epoch: %d\" % epoch,\"Training Acc: %6.2f\"% train_acc[epoch],\"Validation Acc: %6.2f\"% val_acc[epoch])\n",
        "  \n",
        "  #Save model\n",
        "  model_path = get_model_name(net.name,batch_size,learning_rate,epoch)\n",
        "  torch.save(net.state_dict(),model_path)\n",
        "\n",
        "  plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
        "  plt.plot(epochs,train_acc,label=\"Training Acc\")\n",
        "  plt.plot(epochs,val_acc,label=\"Validation Acc\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.title(\"Training Loss vs Validation Loss\")\n",
        "  plt.plot(epochs,train_loss,label=\"Training Loss\")\n",
        "  plt.plot(epochs,val_loss,label=\"Val Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Final Training Acc: %6.2f\"% train_acc[-1],\"Final Validation Acc: %6.2f\"% val_acc[-1])"
      ],
      "metadata": {
        "id": "9NL49NGfmeiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_net = ANNClassifier()\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  first_net.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "\n",
        "train_net(first_net,128,0.0003,40)"
      ],
      "metadata": {
        "id": "niO78eianhd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_net = ANNClassifier()\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  first_net.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "\n",
        "state = torch.load('/content/drive/MyDrive/APS360/models/model_ANN_bs128_lr0.0003_epoch39')\n",
        "first_net.load_state_dict(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW2X8SmSaDAU",
        "outputId": "90422cb5-3fbd-45b1-c0d7-fd1b8b7819d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(testing_dataset,batch_size=64,shuffle=True)\n",
        "\n",
        "print(\"Testing Accuracy: %6.2f\"% get_accuracy(first_net,test_loader))"
      ],
      "metadata": {
        "id": "s7N8M-7U0Kbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651919f0-1f16-4768-86ed-79bb397f6d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy:   0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(training_dataset,batch_size=64,shuffle=True)\n",
        "print(\"Testing Accuracy: %6.2f\"% get_accuracy(first_net,test_loader))"
      ],
      "metadata": {
        "id": "SYxlZ9XofJXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_net = GestureNet()\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  second_net.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "\n",
        "train_net(second_net,128,0.008,30)"
      ],
      "metadata": {
        "id": "mXMsOIpSWIo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_training = ResNetANNClassifier()\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  resnet_training.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "\n",
        "train_net(resnet_training,64,0.0001,35)"
      ],
      "metadata": {
        "id": "fILM6zxy6Lxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_training = ResNetANNClassifier()\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  resnet_training.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "\n",
        "train_net(resnet_training,256,0.001,35)"
      ],
      "metadata": {
        "id": "wdP2d2OMCiPR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}